[[chapter_02_repository]]
== Repository Pattern

In the previous chapter we built a simple domain model that can allocate orders
to batches of stock. It's easy for us to write tests against this code because
there aren't any dependencies or infrastructure to set up. If we needed to run
a database or an API and create test data, our tests would be harder to write
and maintain.

Sadly, at some point we'll need to put our perfect little model in the hands of
users and we'll need to contend with the real world of spreadsheets and web
browsers and race conditions. For the next few chapters we're going to look at
how we can connect our idealised domain model to external state.

We expect to be working in an agile manner, so our priority is to get to an MVP
as quickly as possible.  In our case that's going to be a web API. In a real
project, you might dive straight in with some end-to-end tests and start
plugging in a web framework, test-driving things outside-in.

But we know that, no matter what, we're going to need some form of persistent
storage, and this is a textbook, so we can allow ourselves a tiny bit more
bottom-up development, and start to think about storage and databases.


=== Some pseudocode: what are we going to need?

When we build our first API endpoint, we know we're going to have
some code that looks more or less like <<api_endpoint_pseudocode>>:


[[api_endpoint_pseudocode]]
.What our first API endpoint will look like
====
[role="skip"]
[source,python]
----
@flask.route('/allocate')
def allocate_endpoint():
    # extract order line from request
    line = OrderLine(request.params #...)
    # load all batches from the DB
    batches = #...
    # call our domain service
    allocate(line, batches)
    # then save the allocation back to the database somehow
    return 201
----
====

We'll need a way to retrieve batch info from the DB and instantiate our domain
model objects from it, and we'll also need a way of saving them back to the
database.


=== Applying the Dependency Inversion Principle to the Database

As mentioned in <<part1_prologue>>, the "layered architecture" is a common
approach to structuring an system that has a UI, some logic, and a database:  


[[layered_architecture2]]
.Layered Architecture
====
[role="skip"]
[source,text]
----
+-------------------------------------------------+
|              Presentation Layer                 |
+-------------------------------------------------+
                      |
                      V
+-------------------------------------------------+
|               Business Logic                    |
+-------------------------------------------------+
                      |
                      V
+-------------------------------------------------+
|                Database Layer                   |
+-------------------------------------------------+
----
====

Django's Model-View-Template structure is closely related, as is
Model-View-Controller (MVC). In any case, the aim is to keep the layers
separate (which is a good thing), and to have each layer depend only on the one
below...

But we want our domain model to have _no dependencies whatsoever_. We don't
want infrastructure concerns bleeding over into our domain model and slowing
down our unit tests or our ability to make changes.
//TODO (DS) Is 'no dependencies whatsoever' an overstatement? E.g. there'd be
//no problem depending on certain stdlib packages such as abc. 

Instead, as discussed in the prologue, we'll think of our model as being on the
"inside", and dependencies flowing inwards to it;  what people sometimes call
"onion architecture".

[[onion_architecture]]
.Onion Architecture
====
[role="skip"]
[source,text]
----
+------------------------+   
|   Presentation Layer   |   
+------------------------+   
           |                 
           V                 
   +---------------------------------------------------+
   |                   Domain model                    |
   +---------------------------------------------------+
                                        ^                 
                                        |                 
                               +-------------------+
                               |   Database Layer  |
                               +-------------------+
----
====

.Is this Ports and Adapters?
*******************************************************************************
> "Is this Ports and Adapters?  Or is it Hexagonal Architecture?  Is it the same
> as the Onion architecture?  What about the Clean architecture?  What's a Port
> and what's an Adapter?  Why do you people have so many words for the same thing?

Although some people like to nitpick over the differences, all these are
pretty much names for the same thing, and they all boil down to the
Dependency Inversion Principle--high-level modules (the domain) should
not depend on low-level ones (the infrastructure).footnote:[Mark Seeman has
https://blog.ploeh.dk/2013/12/03/layers-onions-ports-adapters-its-all-the-same/[an excellent blog post]
on the topic, which we recommend.]

We'll get into some of the nitty-gritty around "depending on abstractions",
and whether there is a Pythonic equivalent of interfaces, later in the book.
*******************************************************************************


==== The "normal" ORM way: model depends on ORM.

In 2019 it's unlikely that your team are hand-rolling their own SQL queries.
Instead, you're almost certainly using some kind of framework to generate
SQL for you based on your model objects.

These frameworks are called Object-Relational Mappers because they exist to
bridge the conceptual gap between the world of objects and domain modelling, and
the world of databases and relational algebra.

The most important thing an ORM gives us is "persistence ignorance": the idea
that our fancy domain model doesn't need to know anything about how data are
loaded or persisted. This helps to keep our domain clean of dependencies.
//TODO (DS): Might be interesting to point out that orms are following the DIP themselves...

But if you follow the typical SQLAlchemy tutorial, you'll end up with something
like this:


[[typical_sqlalchemy_example]]
.SQLAlchemy "declarative" syntax, model depends on ORM (orm.py)
====
[role="skip"]
[source,python]
----
from sqlalchemy import Column, ForeignKey, Integer, String
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import relationship

Base = declarative_base()

class Order(Base):
    id = Column(Integer, primary_key=True)

class OrderLine(Base):
    id = Column(Integer, primary_key=True)
    sku = Column(String(250))
    qty = Integer(String(250))
    order_id = Column(Integer, ForeignKey('order.id'))
    order = relationship(Order)

class Allocation(Base):
    #... and so on
----
====

You don't need to understand SQLAlchemy to see that our pristine model is now
full of dependencies on the ORM, and is starting to look ugly as hell besides.
Can we really say this model is ignorant of the database? How can it be
separate from storage concerns when our model properties are directly coupled
to database columns?

.Django's ORM is essentially the same, but more restrictive
*******************************************************************************

If you're more used to Django, the SQLAlchemy snippet above translates to
something like this:

[[django_orm_example]]
.Django ORM example
====
[source,python]
[role="skip"]
----
class Order(models.Model):
    pass

class OrderLine(models.Model):
    sku = models.CharField(max_length=255)
    qty = models.IntegerField()
    order = models.ForeignKey(Order)

class Allocation(models.Model):
    #... and so on
----
====

The point is the same -- our model classes inherit directly from ORM
classes, so our model depends on the ORM.  We want it to be the other
way around.

Django doesn't provide an equivalent for SQLAlchemy's "classical mapper",
but see <<appendix_django>> for some examples of how you apply dependency
inversion and the Repository Pattern to Django.

*******************************************************************************



==== Inverting the dependency: ORM depends on model.

Well, thankfully, that's not the only way to use SQLAlchemy.  The alternative is
to define your schema separately, and an explicit _mapper_ for how to convert
between the schema and our domain model:

https://docs.sqlalchemy.org/en/latest/orm/mapping_styles.html#classical-mappings


[[sqlalchemy_classical_mapper]]
.Explicit ORM Mapping with SQLALchemy Table objects (orm.py)
====
[source,python]
----
from sqlalchemy.orm import mapper, relationship

import model  #<1>


metadata = MetaData()

order_lines = Table(  #<2>
    'order_lines', metadata,
    Column('id', Integer, primary_key=True, autoincrement=True),
    Column('sku', String(255)),
    Column('qty', Integer, nullable=False),
    Column('orderid', String(255)),
)
#...


def start_mappers():
    lines_mapper = mapper(model.OrderLine, order_lines)  #<3>
----
====

<1> The ORM imports the domain model, and not the other way around

<2> We define our database tables and columns using SQLAlchemy's abstractions.

<3> And when we call the `mapper` function, SqlAlchemy does its magic to bind
    our domain model classes to the various tables we've defined.

The end result will be that, if we call `start_mappers()`, we will be able to
easily load and save domain model instances from and to the database. But if
we never call that function, then our domain model classes stay blissfully
unaware of the database.

This gives us all the benefits of SQLAlchemy, including the ability to use
`alembic` for migrations, and the ability to transparently query using our
domain classes, as we'll see.

// TODO: mention hack: `@dataclass(frozen=True)` -> `dataclass(unsafe_hash=True)`

When you're first trying to build your ORM config, it can be useful to write
some tests for it, as in <<orm_tests>>:


[[orm_tests]]
.Testing the ORM directly (throwaway tests) (test_orm.py)
====
[source,python]
----
def test_orderline_mapper_can_load_lines(session):  #<1>
    session.execute(  #<1>
        'INSERT INTO order_lines (orderid, sku, qty) VALUES '
        '("order1", "sku1", 12),'
        '("order1", "sku2", 13),'
        '("order2", "sku3", 14)'
    )
    expected = [
        model.OrderLine('order1', 'sku1', 12),
        model.OrderLine('order1', 'sku2', 13),
        model.OrderLine('order2', 'sku3', 14),
    ]
    assert session.query(model.OrderLine).all() == expected


def test_orderline_mapper_can_save_lines(session):
    new_line = model.OrderLine('order1', 'sku1', 12)
    session.add(new_line)
    session.commit()

    rows = list(session.execute('SELECT orderid, sku, qty FROM "order_lines"'))
    assert rows == [('order1', 'sku1', 12)]
----
====

<1> If you've not used pytest, the `session` argument to this test needs
    explaining.  You don't need to worry about the details of pytest or its
    fixtures for the purposes of this book, but the short explanation is that
    you can define common dependencies for your tests as "fixtures", and
    pytest will inject them to the tests that need them by looking at their
    function arguments.  In this case, it's a SQLAlchemy database session.


You probably wouldn't keep these tests around--as we'll see shortly, once
you've taken the step of inverting the dependency of ORM and domain model, it's
only a small additional step to implement an additional abstraction called the
Repository pattern, which will be easier to write tests against, and will
provide a simple, common interface for faking out later in tests.

// TODO (DS): Not sure how valuable this bit about getting the orm directly is.
// Perhaps it would make more sense to start with the abstraction (repository)
// and then show how to use sqlalchemy to plug in the implementation.

But we've already achieved our objective of inverting the traditional
dependency: the domain model stays "pure" and free from infrastructure
concerns.  We could throw away SQLAlchemy and use a different ORM, or a totally
different persistence system, and the domain model doesn't need to change at
all.


Depending on what you're doing in your domain model, and especially if you
stray far from the OO paradigm, you may find it increasingly hard to get the
ORM to produce the exact behaviour you need,  and you may need to modify your
domain modelfootnote:[Shout out to the amazingly helpful SQLAlchemy
maintainers, and Mike Bayer in particular].  As so often with
architectural decisions, there is a trade-off you'll need to consider.  As the
Zen of Python says, "Practicality beats purity!"

At this point though, our flask API endpoint might look something like
<<api_endpoint_with_session>>, and we could get it to work just fine.

[[api_endpoint_with_session]]
.Using SQLAlchemy directly in our API endpoint
====
[role="skip"]
[source,python]
----
@flask.route('/allocate')
def allocate_endpoint():
    session = start_session()

    # extract order line from request
    line = OrderLine(
        request.params['order_id'], 
        request.params['sku'], 
        request.params['qty'], 
    )

    # load all batches from the DB
    batches = session.query(Batch).all()

    # call our domain service
    allocate(line, batches)

    # save the allocation back to the database
    session.commit()

    return 201
----
====



=== Introducing Repository Pattern.

The repository pattern is an abstraction over persistent storage. It hides the
boring details of data access by pretending that all of our data is in memory.

If we had infinite memory in our laptops, we'd have no need for clumsy databases.
Instead, we could just use our objects whenever we liked. What would that look
like?

[[all_my_data]]
.You've got to get your data from somewhere
====
[role="skip"]
[source,python]
----
import all_my_data

def create_a_batch(self):
    batch = Batch(...)
    all_my_data.batches.add(batch)

def modify_a_batch(self, batch_id, new_quantity):
    batch = all_my_data.batches.get(batch_id)
    batch.change_initial_quantity(new_quantity)

----
====


Even though our objects are in memory, we need to put them _somewhere_ so we can
find them again. Our in memory data would let us add new objects, just like a
list or a set, and since the objects are in memory we never need to call a
"Save" method, we just fetch the object we care about, and modify it in memory.

The ideal repository has just two methods: `add` to put a new item in the
repository, and `get` to return a previously added item. We stick rigidly to
using these methods for data access in our domain and our _service layer_. This
self-imposed simplicity stops us from coupling our domain model to the database.
//TODO what about delete and update?

[[repository_pattern_diagram]]
.Repository pattern
====
[role="skip"]
[source,text]
----
TODO ok fix this diagram

               +----------------------------+   
               | Presentation Layer (Flask) |   
               +----------------------------+   
                             |                 
                             V                 
   +---------------------------------------------------+
   |                   Service layer                   |
   +---------------------------------------------------+
             |                 
             V
   +-------------------+            +-------------------+
   |   Repository      |   -->      |   Database        |
   +-------------------+            +-------------------+
             |                           |                 
             V                           V                 
   +---------------------------------------------------+
   |                   Domain model                    |
   +---------------------------------------------------+
----
====

Whenever we introduce an architectural pattern in this book, we'll always be
trying to ask: "what do we get for this?  And what does it cost us?". Rich
Hickey once said "programmers know the benefits of everything and the tradeoffs
of nothing".

Usually at the very least we'll be introducing an extra layer of abstraction,
and although we may hope it will be reducing complexity overall, it does add
complexity locally, and it has a cost in terms raw numbers of moving parts and
ongoing maintenance.

Repository pattern is probably one of the easiest choices in the book though,
if you've already heading down the DDD and dependency inversion route.  As far
as our code is concerned, we're really just swapping the SQLAlchemy abstraction
(`session.query(Batch)`) for a different one (`batches_repo.get`) which we
designed.

We will have to write a few lines of code in our repository class each time we
add a new domain object that we want to retrieve, but in return we get a very
simple abstraction over our storage layer, which we control. It would make
it very easy to make fundamental changes to the way we store things (see
<appendix_csvs>>), and as we'll see, it is very easy to fake out for unit tests.

In addition, "Repository pattern" is so common in the DDD world that, if you
do collaborate with programmers that have come to Python from the Java and C#
worlds, they're likely to recognise it.

As always we start with a test.  Unlike the ORM tests from earlier, these tests
are good candidates for staying part of your codebase longer term, particularly
if any parts of your domain model mean the object-relational map is nontrivial.


[[repo_test_save]]
.Repository test for saving an object (test_repository.py)
====
[source,python]
----
def test_repository_can_save_a_batch(session):
    batch = model.Batch('batch1', 'sku1', 100, eta=None)

    repo = repository.BatchRepository(session)
    repo.add(batch)
    session.commit()

    rows = list(session.execute(
        'SELECT reference, sku, _purchased_quantity, eta FROM "batches"'
    ))
    assert rows == [('batch1', 'sku1', 100, None)]
----
====

//TODO (DS) - Intuitively this test feels a little strange, mixing the add
//method of the repo with raw SQL to check it's there. I would lean towards
//either checking everything using its interface (i.e. adding to the repo, then
//using the repo to get it back) or else testing that the add method executed
//the SQL I was expecting. I'm not saying this way is worse - maybe it's better
//- but I'd like to know why! 

The next test involves retrieving batches and allocations so it's more
complex:


[[repo_test_retrieve]]
.Repository test for retrieving a complex object (test_repository.py)
====
[source,python]
----
def insert_order_line(session):
    session.execute(
        'INSERT INTO order_lines (orderid, sku, qty) VALUES ("order1", "sku1", 12)'
    )
    [[orderline_id]] = session.execute(
        'SELECT id FROM order_lines WHERE orderid=:orderid AND sku=:sku',
        dict(orderid='order1', sku='sku1')
    )
    return orderline_id


def insert_batch(session, batch_id):  #<1>
    #...

def test_repository_can_retrieve_a_batch_with_allocations(session):
    orderline_id = insert_order_line(session)
    batch1_id = insert_batch(session, 'batch1')
    insert_batch(session, 'batch2')
    insert_allocation(session, orderline_id, batch1_id)

    repo = repository.BatchRepository(session)
    retrieved = repo.get('batch1')

    expected = model.Batch('batch1', 'sku1', 100, eta=None)
    assert retrieved == expected  # Batch.__eq__ only compares reference
    assert retrieved.sku == expected.sku
    assert retrieved._purchased_quantity == expected._purchased_quantity
    assert retrieved._allocations == set(
        model.OrderLine('order1', 'sku1', 12)
    )
----
====

<1> We'll spare you the details of the raw SQL for `insert_batch` and
    `insert_allocation`.

//TODO (HP) that assert retrieved == expected doesnt actually work. fix.

//TODO (DS): This is hard to follow (particularly as we're not *that* familiar
//with the data model). I've actually forgotten what a batch is, so I had to
//flip back to remind myself. I think we need more help to understand what's
//going on from a domain perspective. Maybe a table diagram, or at least
//some comments, would allow a reader to skim it for understanding. 

//Picking a descriptive SKU (e.g. 'comfy-sofa') would make this a bit more fun to read. 

// Personally I'd find ol_id or even order_line_id easier to read. Same with b1id - batch1_id would be easier.

// Worth explaining why we have to do a follow up query to get the id inserted?j

// Why the underscore in _allocations here?

Whether or not you painstakingly write tests for every model is a judgement
call.  Once you have one class tested for create/modify/save, you might be
happy to go on and do the others with a minimal roundtrip test, or even nothing
at all, if they all follow a similar pattern.  In our case, the ORM config
that sets up the `._allocations` set is a little complex, so it merited a
specific test.


You end up with something like <<batch_repository>>:


[[batch_repository]]
.A typical repository (repository.py)
====
[source,python]
----
class BatchRepository:

    def __init__(self, session):
        self.session = session

    def add(self, batch):
        self.session.add(batch)

    def get(self, reference):
        return self.session.query(model.Batch).filter_by(reference=reference).one()

    def list(self):
        return self.session.query(model.Batch).all()
----
====

//TODO (DS) This is the first time we've seen the concrete implementation of an
//abstraction. It's really important that readers understand that you've
//already defined an interface (implicitly) which you're now implementing -
//people might miss this. This might be a good point to discuss using an
//abstract base class so that we know we're implementing the interface fully. 

And now our flask endpoint might look something like <<api_endpoint_with_repo>>:

[[api_endpoint_with_repo]]
.Using our repository directly in our API endpoint
====
[role="skip"]
[source,python]
----
@flask.route.gubbbins
def allocate_endpoint():
    batches = BatchRepository.list()
    lines = [OrderLine(l['orderid'], l['sku'], l['qty']) for l in lines]
    allocate(lines, batches)
    session.commit()
    return 201
----
====


=== Building a fake repository for tests is now trivial!

Here's one of the biggest benefits of Repository pattern.


//TODO (DS)As mentioned before, might be better to start with the fake before
//mentioning sqlalchemy at all. 


[[fake_repository]]
.A simple fake repository subclassing set (repository.py)
====
[role="skip"]
[source,python]
----
class FakeRepository(set):

    def get(self, reference):
        return next(obj for obj in self if obj.reference == reference)
----
====

Because we subclass `set` we get the `.add()` method for free, and
`.get()` is a one-liner.

Using a fake repo in tests is really easy, and we have a simple
abstraction that's easy to use and reason about:

[[fake_repository_example]]
.Example usage of fake repository (test_api.py)
====
[role="skip"]
[source,python]
----
fake_repo = FakeRepository([batch1, batch2, batch3])
----
====

NOTE: You can read a bit more about our thinking on abstractions in
    <<appendix_abstractions>>.  There's good stuff in there!

//TODO: move abstractions appendix into main body of book as
// a proper chapter

How do we actually instantiate these repositories, fake or real?
What will our flask app actually look like?  Find out in the next
exciting instalment...


.Repository pattern: recap
*****************************************************************
Apply Dependency Inversion to your ORM::
    Our domain model should be free of infrastructure concerns,
    so your ORM should import your model, and not the other way
    around.

Repository pattern is a simple abstraction around permanent storage::
    The repository gives you the illusion of a collection of in-memory
    objects. It makes it very easy to create a `FakeRepository` for
    testing, and it makes it easy to swap fundamental details of you
    infrastructure without disrupting your core application. See
    <<appendix_csvs>> for an example.

*****************************************************************
