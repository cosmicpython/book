[[chapter_06_events_and_message_bus]]
== Events And The Message Bus

So far we've spent a lot of time and energy on a simple problem that we could
easily have solved with Django. You might be asking if the increased testability
and expressiveness are *really* worth all the effort.

In practice, though, we find that it's not the obvious features that make a mess
of our codebases: it's the goop around the edge. It's reporting, and permissions
and workflows that touch a zillion objects.

Let's see how our architecture holds up once we need to plug in some of the
mundane stuff that makes up so much of our systems.

Another day, another new requirement:  when we can't allocate an order because
we're out of stock, we should alert the buying team. They'll go and fix the
problem by buying more stock, and all will be well.

For a first version, our product owner says we can just send the alert by email.

=== Avoiding Making A Mess.

==== First, Avoid Making A Mess Of Of Our Web Controllers

When we have a new requirement like this, that's not _really_ to do with the
core domain, it's all too easy to start dumping these things into our web
controllers:


[[email_in_flask]]
.Just whack it in the endpoint, what could go wrong? (src/allocation/flask_app.py)
====
[source,python]
[role="skip"]
----
@app.route("/allocate", methods=['POST'])
def allocate_endpoint():
    line = model.OrderLine(
        request.json['orderid'],
        request.json['sku'],
        request.json['qty'],
    )
    try:
        batchref = services.allocate(line, unit_of_work.start)
    except (model.OutOfStock, services.InvalidSku) as e:
        send_mail(
            'out of stock', 
            'stock_admin@made.com', 
            f'{line.orderid} - {line.sku}'
        )
        return jsonify({'message': str(e)}), 400

    return jsonify({'batchref': batchref}), 201
----
====

As a one-off hack, this might be okay, but it's easy to see how we can quickly
end up in a mess by patching things in this way. Sending emails isn't the job of
our HTTP layer, and we'd like to be able to unit test this new feature.

Let's start with a unit test written against our service layer.

[[mocky_test_for_send_email]]
.A Mocky test at the service layer (tests/unit/test_services.py)
====
[source,python]
[role="non-head"]
----
def test_sends_email_on_out_of_stock_error():
    uow = FakeUnitOfWork()
    services.add_batch('b1', 'sku1', 9, None, uow)

    with mock.patch('allocation.email.send_mail') as mock_send_mail:  #<1>
        with pytest.raises(exceptions.OutOfStock):
            services.allocate('o1', 'sku1', 10, uow)
        assert mock_send_mail.call_args == mock.call(  #<2>
            'stock@made.com',
            f'Out of stock for sku1',
        )
----
====

<1> We use `unittest.mock.patch` to monkeypatch out our "real" email-sending
    function, which lives at _src/allocation/email.py_.  This may not be the best
    pattern for testing dependencies like email. In the next chapter we'll discuss
    alternative ways of approaching this.


NOTE: If you find yourself using `unittest.mock` to test external dependencies
    at the service layer, it may be a code smell.  See
    <<chapter_10_dependency_injection>>.


==== ... And Let's Not Make A Mess Of Our Model Either

Assuming we don't want to put this code into our web controllers, because
we want them to be as thin as possible, we may look at putting it right at
the source, in the model:

[[email_in_model]]
.Email-sending code in our model isn't lovely either (src/allocation/model.py)
====
[source,python]
[role="non-head"]
----
    def allocate(self, line: OrderLine) -> str:
        try:
            batch = next(
                b for b in sorted(self.batches) if b.can_allocate(line)
            )
            #...
        except StopIteration:
            email.send_mail('stock@made.com', f'Out of stock for {line.sku}')
            raise exceptions.OutOfStock(f'Out of stock for sku {line.sku}')
----
====

But that's even worse!  We don't want our model to have any dependencies on
infrastructure concerns like `email.send_mail`.


==== Or The Service Layer!

In the service layer it's a little better, but it's still not lovely:

[[email_in_services]]
.And in the services layer it's no better (src/allocation/services.py)
====
[source,python]
[role="non-head"]
----
def allocate(
        orderid: str, sku: str, qty: int,
        uow: unit_of_work.AbstractUnitOfWork
) -> str:
    line = OrderLine(orderid, sku, qty)
    with uow:
        product = uow.products.get(sku=line.sku)
        if product is None:
            raise exceptions.InvalidSku(f'Invalid sku {line.sku}')
        try:
            batchref = product.allocate(line)
            uow.commit()
            return batchref
        except exceptions.OutOfStock:
            email.send_mail('stock@made.com', f'Out of stock for {line.sku}')
            raise
----
====

Catching an exception and re-raising it?  I mean, it could be worse, but it's
definitely making us unhappy.


=== Single Responsibility Principle

Really this is a violation of the Single Responsibility Principle.  Our use
case is allocation. Our endpoint, service function, and domain methods are all
called `allocate`, not `allocate_and_send_mail_if_out_of_stock`.

NOTE: Rule of thumb: if you can't describe what your class does without using
    words like "then" or "and," you might be violating SRP.

This email sending thing is unwelcome *goop* messing up the nice clean flow
of our system. What we'd like is to keep our domain model focused on the rule
"You can't allocate more stuff than is actually available." 

The domain model's job is to know that we're out of stock, but the
responsibility of sending an alert belongs elsewhere. We should be able to turn
this feature on or off, or to switch to SMS notifications instead, without
needing to change the rules of our domain model.

We'd also like to keep the service layer free of implementation details. We
want to apply the Dependency Inversion Principle to notifications, so that our
service layer depends on an abstraction, in the same way as we avoid depending
on the database by using a UnitOfWork.

=== All Aboard The Message Bus!

The patterns we're going to introduce here are _Domain Events_ and the _Message Bus_.

First, rather than being concerned about emails, our model will be in charge of
recording "events"--facts about things that have happened. We'll use a Message
Bus to respond to events, and invoke some new operation.


==== The Model Records Events

[[domain_event]]
.The model records a domain event (src/allocation/model.py)
====
[source,python]
[role="non-head"]
----
class Product:

    def __init__(self, sku: str, batches: List[Batch], version_number: int = 0):
        self.sku = sku
        self.batches = batches
        self.version_number = version_number
        self.events = []  # type: List[events.Event]  #<1>

    def allocate(self, line: OrderLine) -> str:
        try:
            #...
        except StopIteration:
            self.events.append(events.OutOfStock(line.sku))  #<2>
            # raise exceptions.OutOfStock(f'Out of stock for sku {line.sku}')  #<3>
            return None
----
====

<1> Our Aggregate grows a `.events` attribute, where it will store facts
    about what has happened.

<2> Rather than invoking some email-sending code directly, we record those
    events at the place they occur, using only the language of the domain.

<3> We're also going to stop raising an exception for the out-of-stock 
    case.  The event will do the job the exception was doing.

TIP: Exceptions and Events don't mix.  If you're implementing domain
    events, don't raise exceptions to describe the same domain concept.
    As we'll see later when we handle events in the unit of work, it's
    confusing to have to reason about events and exceptions together.

TODO: This ^^^ is true, but I think the real problem is that you shouldn't use
exceptions for control-of-flow. It's like a classic design smell.


==== Events Are Simple Dataclasses

Events are part of our domain.  We could store them in _model.py_, but we
may as well keep them in their own file.  (this might be a good time to
consider refactoring out a directory called "domain," so we have _domain/model.py_
and _domain/events.py_).

[[events_dot_py]]
.Event classes (src/allocation/events.py)
====
[source,python]
----
from dataclasses import dataclass

class Event:  #<1>
    pass

@dataclass
class OutOfStock(Event):  #<2>
    sku: str
----
====


<1> Once we have a number of events we'll find it useful to have a parent
    class that can store common behaviour.  It's also useful for type
    hints in our message bus, as we'll see shortly.

<2> `dataclasses` are great for domain events too.



==== The Message Bus Maps Events To Handlers

A message bus essentially says: when I see this event, I should
invoke the following handlers.  Here's a minimal implementation:

[[messagebus]]
.Simple message bus (src/allocation/messagebus.py)
====
[source,python]
----
def handle(events_: List[events.Event]):
    while events_:
        event = events_.pop(0)
        for handler in HANDLERS[type(event)]:
            handler(event)


def send_out_of_stock_notification(event: events.OutOfStock):
    email.send_mail(
        'stock@made.com',
        f'Out of stock for {event.sku}',
    )


HANDLERS = {
    events.OutOfStock: [send_out_of_stock_notification],

}  # type: Dict[Type[events.Event], List[Callable]]
----
====

//TODO: maybe handle should just take one event?


==== In A First Cut, The Service Layer Puts Events On The Message Bus

And now we need something to catch events from the model and pass
them to the message bus.  The service layer might be one place to do
it...

[[service_talks_to_messagebus]]
.The service layer with an explicit message bus (src/allocation/services.py)
====
[source,python]
[role="non-head"]
----
def allocate(
        orderid: str, sku: str, qty: int,
        uow: unit_of_work.AbstractUnitOfWork
) -> str:
    line = OrderLine(orderid, sku, qty)
    with uow:
        product = uow.products.get(sku=line.sku)
        if product is None:
            raise exceptions.InvalidSku(f'Invalid sku {line.sku}')
        try:  #<1>
            batchref = product.allocate(line)
            uow.commit()
            return batchref
        finally:  #<1>
            messagebus.handle(product.events)  #<2>
----
====

<1> We keep the `try/finally` from our ugly earlier implementation,
<2> But now instead of depending directly on some email infrastructure,
    the service layer is just in charge of passing events from the model
    up to the message bus.

That avoids some of the ugliness that we had in our naive implementation,
but we can do better.


TODO: discussion, service layer can/could raise events directly too.


=== The Unit Of Work Can Pass Events To The Message Bus

The UoW already has a `try/finally`, and it knows about all the aggregates
currently in play because it provides access to the _Repository_.  So it's
a good place to spot events and pass them to the message bus:

////
TODO
In Example 9. The UoW meets the Message Bus (src/allocation/unit_of_work.py), I got stuck trying to figure out where the seen attribute had come from.
It might be helpful to add a line explicitly introducing it before Example 9.
Once I read on to Example 10 everything cleared up immediately.

https://github.com/python-leap/book/issues/35
////
[[uow_with_messagebus]]
.The UoW meets the message bus (src/allocation/unit_of_work.py)
====
[source,python]
----
class AbstractUnitOfWork(abc.ABC):
    ...

    def commit(self):
        self._commit()  #<1>
        for obj in self.products.seen:  #<2>
            messagebus.handle(obj.events)

    @abc.abstractmethod
    def _commit(self):
        raise NotImplementedError

...

class SqlAlchemyUnitOfWork(AbstractUnitOfWork):
    ...

    def _commit(self):  #<1>
        self.session.commit()
----
====

<1> We'll change our commit method to require a private `._commit()`
    method from subclasses

<2> After committing, we run through all the objects that our
    repository has seen and pass their events to the message bus.

That relies on the repository keeping track of aggregates that it's seen:

[[repository_tracks_seen]]
.Repository tracks aggregates seen (src/allocation/repository.py)
====
[source,python]
----
class AbstractRepository(abc.ABC):

    def __init__(self):
        self.seen = set()  # type: Set[model.Product]  #<1>

    def add(self, product):  #<2>
        self._add(product)
        self.seen.add(product)

    def get(self, sku):  #<3>
        p = self._get(sku)
        if p:
            self.seen.add(p)
        return p

    @abc.abstractmethod
    def _add(self, product):  #<2>
        raise NotImplementedError

    @abc.abstractmethod  #<3>
    def _get(self, sku):
        raise NotImplementedError



class SqlAlchemyRepository(AbstractRepository):

    def __init__(self, session):
        super().__init__()
        self.session = session

    def _add(self, product):  #<2>
        self.session.add(product)

    def _get(self, sku):  #<3>
        return self.session.query(model.Product).filter_by(sku=sku).first()
----
====

<1> We initialise a set to store objects seen.  That means our implementations
    need to call `super().__init__()`

<2> The parent `add()` method adds things to `.seen`, and now requires subclasses
    to implement `._add()`

<3> Similarly, `.get()` delegates to a `._get()` function, to be implemented by
    subclasses, in order to capture objects seen.

Once the UoW and repository collaborate in this way to automatically keep
track of live objects and process their events, the service layer can now be
totally free of event-handling concerns:


[[services_clean]]
.Service layer is clean again (src/allocation/services.py)
====
[source,python]
----
def allocate(
        orderid: str, sku: str, qty: int,
        uow: unit_of_work.AbstractUnitOfWork
) -> str:
    line = OrderLine(orderid, sku, qty)
    with uow:
        product = uow.products.get(sku=line.sku)
        if product is None:
            raise exceptions.InvalidSku(f'Invalid sku {line.sku}')
        batchref = product.allocate(line)
        uow.commit()
        return batchref
----
====


We do also have to remember to change the fakes in the service layer and make them
call `super()` in the right places, and implement underscorey methods, but the
changes are minimal:
////
TODO
In Example 12 we have to go back and update our FakeRepository object.
In a large project with many contributors, it feels to me that keeping these fakes in sync with the real objects might become an issue.
Do you guys have any strategies for dealing with that?
https://github.com/python-leap/book/issues/35
////
[[services_tests_ugly_fake_messagebus]]
.Service-layer fakes need tweaking. (tests/unit/test_services.py)
====
[source,python]
----
class FakeRepository(repository.AbstractRepository):

    def __init__(self, products):
        super().__init__()
        self._products = set(products)

    def _add(self, product):
        self._products.add(product)

    def _get(self, sku):
        return next((p for p in self._products if p.sku == sku), None)

...

class FakeUnitOfWork(unit_of_work.AbstractUnitOfWork):
    ...

    def _commit(self):
        self.committed = True

----
====


=== Unit Testing With A Fake Message Bus

TODO: discuss replacing @mock test with `FakeMessageBus`




=== Wrap-up

TODO - wrap up for domain events chapter



.Recap: Domain Events and the Message Bus
*****************************************************************
Events can help with SRP::
    bla

Unit of Work pattern can help::
    bla bla.

*****************************************************************
